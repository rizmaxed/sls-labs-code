AWSTemplateFormatVersion: "2010-09-09"
Description: CloudFormation template to create an S3 bucket, DynamoDB table, and Lambda functions for managing images.

Resources:
  LabS3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    Properties:
      BucketName: !Join
        - "-"
        - - "lab-bucket"
          - !Ref AWS::AccountId
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref AWS::StackId
      AccessControl: Private
      Tags:
        - Key: "Name"
          Value: "lab-bucket"

  LabImageMetadataTable:
    Type: AWS::DynamoDB::Table
    DeletionPolicy: Delete
    Properties:
      TableName: "lab_image_metadata"
      AttributeDefinitions:
        - AttributeName: "s3_key"
          AttributeType: "S"
      KeySchema:
        - AttributeName: "s3_key"
          KeyType: "HASH"
      BillingMode: PAY_PER_REQUEST
      StreamSpecification:
        StreamViewType: NEW_AND_OLD_IMAGES

  LabLoadDataRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join
        - "-"
        - - "nfc-load-data-role"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref AWS::StackId
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: "LabLoadDataPolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:ListBucket"
                  - "s3:GetObject"
                Resource:
                  - "arn:aws:s3:::nfclabs-share"
                  - "arn:aws:s3:::nfclabs-share/lab-data/lab-7-4/images/*"
              - Effect: "Allow"
                Action:
                  - "s3:PutObject"
                  - "s3:DeleteObject"
                Resource: !Sub "arn:aws:s3:::${LabS3Bucket}/*"
              - Effect: "Allow"
                Action:
                  - "dynamodb:PutItem"
                  - "dynamodb:UpdateItem"
                Resource: !GetAtt LabImageMetadataTable.Arn
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"

  LabLoadDataFunction:
    Type: "AWS::Lambda::Function"
    DependsOn: [LabS3Bucket, LabImageMetadataTable]
    Properties:
      FunctionName: !Join
        - "-"
        - - "lab_load_data"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref AWS::StackId
      Runtime: "python3.9"
      Handler: "index.handler"
      Role: !GetAtt LabLoadDataRole.Arn
      Timeout: 300
      Environment:
        Variables:
          BUCKET_NAME: !Ref LabS3Bucket
          DYNAMODB_TABLE: !Ref LabImageMetadataTable
      Code:
        ZipFile: |
          import boto3
          import os
          import logging
          import datetime
          import random
          import requests
          import base64

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def handler(event, context):
              logger.info('Event: %s', event)

              try:
                  s3 = boto3.client('s3')
                  dynamodb = boto3.resource('dynamodb')
                  table = dynamodb.Table(os.environ['DYNAMODB_TABLE'])

                  destination_bucket = os.environ['BUCKET_NAME']
                  github_api_url = 'https://api.github.com/repos/rizmaxed/sls-labs-code/lab-7-4/data/images'

                  # Step 1: List files in the GitHub folder
                  response = requests.get(github_api_url)
                  response.raise_for_status()
                  files = response.json()

                  for file in files:
                      if file['type'] != 'file':
                          continue

                      file_name = file['name']
                      download_url = file['download_url']
                      logger.info(f"Downloading {file_name} from GitHub")

                      file_response = requests.get(download_url)
                      file_response.raise_for_status()

                      # Step 2: Upload to S3
                      s3.put_object(
                          Bucket=destination_bucket,
                          Key=file_name,
                          Body=file_response.content,
                          ContentType=file_response.headers.get('Content-Type', 'binary/octet-stream')
                      )
                      logger.info(f"Uploaded {file_name} to {destination_bucket}")

                      # Step 3: Write metadata to DynamoDB
                      table.put_item(
                          Item={
                              's3_key': file_name,
                              'content_type': file_response.headers.get('Content-Type', 'binary/octet-stream'),
                              'file_name': file_name,
                              'last_modified_date': datetime.datetime.utcnow().isoformat(),
                              'expires_at': int((datetime.datetime.now() + datetime.timedelta(seconds=random.randint(0, 300))).timestamp())
                          }
                      )
                      logger.info(f"Inserted metadata for {file_name} into DynamoDB")

                  logger.info('All GitHub files processed and loaded into S3 + DynamoDB.')

              except Exception as e:
                  logger.error('Exception occurred: %s', e)
                  raise

  LabDynamoDBStreamFunction:
    Type: "AWS::Lambda::Function"
    DependsOn: [LabImageMetadataTable, LabS3Bucket]
    Properties:
      FunctionName: !Join
        - "-"
        - - "lab_dynamodb_stream_delete"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref AWS::StackId
      Runtime: "python3.9"
      Handler: "index.handler"
      Role: !GetAtt LabDynamoDBStreamRole.Arn
      Timeout: 300
      Environment:
        Variables:
          BUCKET_NAME: !Ref LabS3Bucket
      Code:
        ZipFile: |
          import boto3
          import os
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          def handler(event, context):
              s3 = boto3.client('s3')
              bucket = os.environ['BUCKET_NAME']
              for record in event['Records']:
                  if record['eventName'] == 'REMOVE':
                      s3_key = record['dynamodb']['Keys']['s3_key']['S']
                      try:
                          s3.delete_object(Bucket=bucket, Key=s3_key)
                          logger.info(f'Deleted S3 object: {s3_key}')
                      except Exception as e:
                          logger.error(f'Failed to delete S3 object {s3_key}: {e}')

  LabDynamoDBStreamMapping:
    Type: "AWS::Lambda::EventSourceMapping"
    DependsOn: [LabDynamoDBStreamFunction, LabImageMetadataTable]
    Properties:
      EventSourceArn: !GetAtt LabImageMetadataTable.StreamArn
      FunctionName: !GetAtt LabDynamoDBStreamFunction.Arn
      StartingPosition: "TRIM_HORIZON"
      BatchSize: 100
      Enabled: true

  LabDynamoDBStreamRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Join
        - "-"
        - - "nfc-dynamodb-stream-role"
          - !Select
            - 0
            - !Split
              - "-"
              - !Select
                - 2
                - !Split
                  - "/"
                  - !Ref AWS::StackId
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "lambda.amazonaws.com"
            Action: "sts:AssumeRole"
      Policies:
        - PolicyName: "StreamDeletePolicy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: "Allow"
                Action:
                  - "s3:DeleteObject"
                Resource: !Sub "arn:aws:s3:::${LabS3Bucket}/*"
              - Effect: "Allow"
                Action:
                  - "dynamodb:DescribeStream"
                  - "dynamodb:GetRecords"
                  - "dynamodb:GetShardIterator"
                  - "dynamodb:ListStreams"
                Resource: !GetAtt LabImageMetadataTable.StreamArn
              - Effect: "Allow"
                Action:
                  - "logs:CreateLogGroup"
                  - "logs:CreateLogStream"
                  - "logs:PutLogEvents"
                Resource: "arn:aws:logs:*:*:*"
